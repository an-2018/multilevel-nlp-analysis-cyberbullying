{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-15T09:29:36.999022Z",
     "start_time": "2025-04-15T09:29:25.622562Z"
    }
   },
   "source": "!pip install openai requests tiktoken numpy",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create Dataset",
   "id": "6c9007b0fcc7f134"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:29:58.793073Z",
     "start_time": "2025-04-15T10:29:58.781876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "import json\n",
    "dotenv.load_dotenv()"
   ],
   "id": "9da5c54db0490592",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:29:59.035232Z",
     "start_time": "2025-04-15T10:29:59.014187Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = pd.read_csv(\"data/balanced-merged-data.csv\")",
   "id": "363dc966fa115b38",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:30:00.275885Z",
     "start_time": "2025-04-15T10:30:00.257138Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.head()",
   "id": "45237c21ac74d2d7",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fine-tuning gpt-4o-mini-2024-07-18 requires a specially formatted JSONL training file. OpenAI provides the following example in their documentation:",
   "id": "6edeb2f858b26968"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:30:03.473683Z",
     "start_time": "2025-04-15T10:30:03.461647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# separate train and validation sets\n",
    "train, val = dataset.sample(frac=0.8), dataset.sample(frac=0.2)"
   ],
   "id": "f7235e27c7e040cf",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:30:06.523631Z",
     "start_time": "2025-04-15T10:30:06.496662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train.to_json(\"train.jsonl\", orient=\"records\", lines=True)\n",
    "val.to_json(\"val.jsonl\", orient=\"records\", lines=True)"
   ],
   "id": "180a81906c4af441",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:30:08.824289Z",
     "start_time": "2025-04-15T10:30:08.805870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "def anonymize_text(text):\n",
    "    text = re.sub(r'@\\w+', '@user', text)          # usernames\n",
    "    text = re.sub(r'\\b[A-Z][a-z]+\\b', '[NAME]', text)  # names (very naive)\n",
    "    return text\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(anonymize_text)\n",
    "val[\"text\"] = val[\"text\"].apply(anonymize_text)"
   ],
   "id": "e11090a4f6522d02",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:30:44.994151Z",
     "start_time": "2025-04-15T10:30:44.975930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_chat_format(jsonlpath, type=\"train\"):\n",
    "    # Load dataset\n",
    "    df = pd.read_json(jsonlpath, lines=True)\n",
    "\n",
    "    # Define system prompt\n",
    "    system_prompt = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an AI assistant specialized in analyzing text for hateful or abusive language. \"\n",
    "            \"Your task is to classify whether the input reflects harmful, bullying, or offensive speech in an online context.\"\n",
    "            \"You are a classifier AI for hate speech. You do not generate any content yourself.\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Convert each row into the chat-style format\n",
    "    def row_to_chat_format(row):\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                system_prompt,\n",
    "                {\"role\": \"user\", \"content\": row[\"text\"]},\n",
    "                {\"role\": \"assistant\", \"content\": row[\"label\"], \"weight\": 1}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Apply transformation\n",
    "    chat_data = df.apply(row_to_chat_format, axis=1)\n",
    "    \n",
    "    # Save to JSONL\n",
    "    with open(f\"formatted_{type}.jsonl\", \"w\") as f:\n",
    "        for item in chat_data:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "\n"
   ],
   "id": "680ce43eba24672b",
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:30:46.225399Z",
     "start_time": "2025-04-15T10:30:46.117321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "to_chat_format(\"data/training_set.jsonl\", \"train\")\n",
    "to_chat_format(\"data/validation_set.jsonl\", \"val\")"
   ],
   "id": "b3c1b8f4fe90609f",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:38:22.540931Z",
     "start_time": "2025-04-15T09:38:22.501721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Run preliminary checks\n",
    "# \n",
    "# import json\n",
    "# \n",
    "# # Load the training set\n",
    "# with open('data/train.jsonl', 'r', encoding='utf-8') as f:\n",
    "#     training_dataset = [json.loads(line) for line in f]\n",
    "# \n",
    "# # Training dataset stats\n",
    "# print(\"Number of examples in training set:\", len(training_dataset))\n",
    "# print(\"First example in training set:\")\n",
    "# for message in training_dataset:\n",
    "#     print(message)\n",
    "\n",
    "# # Load the validation set\n",
    "# with open('data/val.jsonl', 'r', encoding='utf-8') as f:\n",
    "#     validation_dataset = [json.loads(line) for line in f]\n",
    "# \n",
    "# # Validation dataset stats\n",
    "# print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "# print(\"First example in validation set:\")\n",
    "# for message in validation_dataset[0][\"text\"]:\n",
    "#     print(message)"
   ],
   "id": "cfd4522d8356332e",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:39:45.730562Z",
     "start_time": "2025-04-15T09:39:45.692791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Validate token counts\n",
    "\n",
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\") # default encoding for gpt-4o models. This requires the latest version of tiktoken to be installed.\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = ['data/training_set.jsonl', 'data/validation_set.jsonl']\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)"
   ],
   "id": "21189a914d56d9c9",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:44:03.056077Z",
     "start_time": "2025-04-15T09:44:03.035765Z"
    }
   },
   "cell_type": "code",
   "source": "import os",
   "id": "5a7214919b0f8ed9",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:44:31.295945Z",
     "start_time": "2025-04-15T09:44:31.286888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(os.getenv(\"AZURE_OPENAI_API_KEY\"))\n",
    "print(os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "print(os.getenv(\"API_VERSION\"))"
   ],
   "id": "8a3ce1df2b369a02",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:20:08.665635Z",
     "start_time": "2025-04-15T10:20:01.398332Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install azure-ai-inference",
   "id": "54503d14a5734111",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:31:43.874286Z",
     "start_time": "2025-04-15T10:31:43.256771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Upload fine-tuning files\n",
    "import dotenv\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "endpoint = \"https://hubdemor3dai7450370013.openai.azure.com/\"\n",
    "model_name = \"gpt-4o\"\n",
    "deployment = \"gpt-4o\"\n",
    "\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "print(subscription_key)\n",
    "\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    ")\n",
    "\n",
    "# client = ChatCompletionsClient(\n",
    "#     endpoint=\"https://hubdemor3dai7450370013.services.ai.azure.com/models\",\n",
    "#     credential=AzureKeyCredential(subscription_key)\n",
    "# )\n"
   ],
   "id": "5657c72447959bf4",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:31:56.357037Z",
     "start_time": "2025-04-15T10:31:49.978482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "training_file_name = 'data/formatted_train.jsonl'\n",
    "validation_file_name = 'data/formatted_val.jsonl'\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file = open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file = open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ],
   "id": "db1c81e4d76c6e25",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a customized model\n",
   "id": "46d079c5b3edef67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:31:58.853785Z",
     "start_time": "2025-04-15T10:31:58.338328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-35-turbo-0125\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters. \n",
    "    seed = 105  # seed parameter controls reproducibility of the fine-tuning job. If no seed is specified one will be generated automatically.\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.id)\n",
    "print(response.model_dump_json(indent=2))"
   ],
   "id": "27228f802768b2c2",
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check fine-tuning job status\n",
   "id": "34abd5f83c10cb1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T10:32:03.248490Z",
     "start_time": "2025-04-15T10:32:03.047133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ],
   "id": "ab918dc4f8f82ab7",
   "execution_count": 45,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:54:08.590017Z",
     "start_time": "2025-04-15T09:54:07.854142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10)\n",
    "print(response.model_dump_json(indent=2))"
   ],
   "id": "e8799019310c8547",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T09:54:39.043310Z",
     "start_time": "2025-04-15T09:54:37.677634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.fine_tuning.jobs.checkpoints.list(job_id)\n",
    "print(response.model_dump_json(indent=2))"
   ],
   "id": "cc31cce266c1f990",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analyze your customized model\n",
    "\n",
    "Azure OpenAI attaches a result file named results.csv to each fine-tune job after it completes. You can use the result file to analyze the training and validation performance of your customized model. The file ID for the result file is listed for each customized model, and you can use the Python SDK to retrieve the file ID and download the result file for analysis.\n",
    "\n",
    "The following Python example retrieves the file ID of the first result file attached to the fine-tuning job for your customized model, and then uses the Python SDK to download the file to your working directory for analysis."
   ],
   "id": "1fd3082c2d0d635a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Retrieve the file ID of the first result file from the fine-tuning job\n",
    "# for the customized model.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "if response.status == 'succeeded':\n",
    "    result_file_id = response.result_files[0]\n",
    "\n",
    "retrieve = client.files.retrieve(result_file_id)\n",
    "\n",
    "# Download the result file.\n",
    "print(f'Downloading result file: {result_file_id}')\n",
    "\n",
    "with open(retrieve.filename, \"wb\") as file:\n",
    "    result = client.files.content(result_file_id).read()\n",
    "    file.write(result)"
   ],
   "id": "fa9f7c91d2771cd3",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
